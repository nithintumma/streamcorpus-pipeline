# YAML kba.pipeline config for generating clean_visible and then
## operating lingpipe

kba.pipeline:
  ## pipeline expects strings over stdin, which are typically paths to
  ## streamcorpus.Chunk files.  They can also be some other kind of
  ## opaque byte strings delimited by newlines that your particular
  ## 'loader' is expecting.

  ## put logs inside each chunk file
  embedded_logs: true

  ## the main pipeline log_dir can trigger similar log chunk
  log_dir: data/john-smith/

  ## tmp_dir, some extractors and loaders require this dir to be in
  ## the same file system as their output.  This is also where the
  ## batch_transforms operate.
  tmp_dir: tmp

  ## task_queue specifies the strings that are passed to an extractor
  ## to obtain a Chunk.  The strings might be paths in a file system
  ## or some other source of data.  The task_queue might simply be
  ## stdin, or it might be a more sophisticated shared queue.
  task_queue: stdin

  ## generator of StreamItems
  extractor: john_smith

  ## hyperlink_labels must run after clean_html and before
  ## clean_visible in order for the newlines that it inserted to get
  ## into the clean_visible that lingpipe will operate on.
  incremental_transforms: []
  batch_transforms: [lingpipe]

  loaders: [to_local_chunks]

  to_local_chunks:
    #output_type: inplace
    output_type: otherdir
    output_path: data/john-smith/
    output_name: "john-smith-tagged-by-lingpipe-%(first)s"

  lingpipe:
    pipeline_root: ../third/
    cleanup_tmp_files: false
    ## convert doc-level labels into token-level labels by requiring
    ## particular substrings appear in the strings of a coref chain
    align_labels_by: names_in_chains
    aligner_data:
      ## token substring to require in the names of a coref chains
      names: [john, smith]
      ## identifier of annotator to find in the doc-level Ratings
      annotator_id: bagga-and-baldwin
