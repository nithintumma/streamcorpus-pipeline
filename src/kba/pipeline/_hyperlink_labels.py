#!/usr/bin/env python
'''
Pipeline stage for extracting hyperlinks to particular domains as
labels generated by the author.

This software is released under an MIT/X11 open source license.

Copyright 2012 Diffeo, Inc.
'''
from streamcorpus import Offset, Label, LabelSet, Annotator, OffsetType

import re
from ._clean_visible import make_clean_visible

class hyperlink_labels(object):
    '''
    Finds hyperlinks in clean_html and generate a
    streamcorpus.LabelSet treating the author as the Annotator
    '''
    def __init__(self, config):
        self.config = config

    def href_filter(self, href):
        '''
        Test whether an href string meets criteria specified by
        configuration parameters 'require_abs_url', which means "does
        it look like it is probably an absolute URL?" and
        'domain_substrings'.  It searches for each of the
        domain_substrings in the href individually, and if any match,
        then returns True.

        :param: href string
        :returns bool:
        '''
        if self.config['hyperlink_labels']['require_abs_url']:
            if not href.lower().startswith('http'):
                return False
        if self.config['hyperlink_labels']['domain_substrings']:
            parts = href.split('/')
            if len(parts) < 3:
                return False
            domain = parts[2].lower()
            for substring in self.config['hyperlink_labels']['domain_substrings']:
                if substring in domain:
                    return True            

    def href_anchors(self, clean_html):
        '''
        simple, regex-based extractor of anchor tags, so we can
        compute byte offsets for anchor texts and associate them with
        their href.
        
        Generates tuple(href_string, first_byte, byte_length)
        '''
        anchors_re = re.compile('''(?P<before>(.|\n)*?)(?P<ahref>\<a.*?href="(?P<href>[^"]*)"(.|\n)*?\>)(?P<anchor>(.|\n)*?)(?P<after>\<\/a\>)''', re.I)
        idx = 0
        for m in anchors_re.finditer(clean_html):
            idx += len(m.group('before'))
            href = m.group('href')
            idx += len(m.group('ahref'))
            first = idx
            length = len(m.group('anchor'))
            idx += length + len(m.group('after'))
            yield href, first, length

    def make_label_set(self, clean_html, clean_visible=None):
        '''
        Make a LabelSet for 'author' and the filtered hrefs & anchors
        '''
        annotator = Annotator()
        annotator.annotator_id = 'author'

        labels = []
        for href, first, length in self.href_anchors(clean_html):
            if self.href_filter(href):
                if clean_visible:
                    if not make_clean_visible(clean_html[first:first+length]) == clean_visible[first:first+length]:
                        print href
                        print '\t html: %r' % clean_html[first:first+length]
                        print '\t visi: %r' % clean_visible[first:first+length]
                label = Label()
                label.target_id = href
                label.offset = Offset(
                    type=OffsetType.BYTES, 
                    first=first, length=length, 
                    value=clean_visible[first:first+length],
                    ## the string name of the content field, not the
                    ## content itself :-)
                    content_form='clean_html')
                labels.append(label)

        if labels:
            return LabelSet(annotator=annotator, labels=labels)
        else:
            return None

    def __call__(self, stream_item):
        '''
        Act as an incremental transform in the kba.pipeline
        '''
        if stream_item.body and stream_item.body.clean_html:
            labelset = self.make_label_set(stream_item.body.clean_html,
                                           stream_item.body.clean_visible)
            if labelset:
                stream_item.body.labelsets.append( labelset )
        return stream_item

if __name__ == '__main__':
    from streamcorpus import StreamItem, ContentItem
    stream_item = StreamItem()
    stream_item.body = ContentItem()
    stream_item.body.clean_html = open('nytimes-index-clean.html').read()
    print hyperlink_labels({'hyperlink_labels':{'require_abs_url': True, 'domain_substrings': ['nytimes.com']}})(stream_item)
    
