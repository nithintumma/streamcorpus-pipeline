#!/usr/bin/env python
'''
Pipeline stage for extracting hyperlinks to particular domains as
labels generated by the author.

This software is released under an MIT/X11 open source license.

Copyright 2012 Diffeo, Inc.
'''
from streamcorpus import Offset, Label, LabelSet, Annotator, OffsetType

import re
from ._clean_visible import make_clean_visible

anchors_re = re.compile('''(?P<before>(.|\n)*?)''' + \
                        '''(?P<ahref>\<a(.|\n)*?href''' + \
                        '''(?P<preequals>(\s|\n)*)=(?P<postequals>(\s|\n)*)''' + \
                        '''(?P<quote>("|')?)(?P<href>[^"]*)(?P=quote)''' + \
                        '''(?P<posthref>(.|\n)*?)\>)''' + \
                        '''(?P<anchor>(.|\n)*?)(?P<after>\<\/a\>)''', re.I)

class hyperlink_labels(object):
    '''
    Finds hyperlinks in clean_html and generate a
    streamcorpus.LabelSet treating the author as the Annotator
    '''
    def __init__(self, config):
        self.config = config

    def href_filter(self, href):
        '''
        Test whether an href string meets criteria specified by
        configuration parameters 'require_abs_url', which means "does
        it look like it is probably an absolute URL?" and
        'domain_substrings'.  It searches for each of the
        domain_substrings in the href individually, and if any match,
        then returns True.

        :param: href string
        :returns bool:
        '''
        if self.config['require_abs_url']:
            if not href.lower().startswith('http'):
                return False
        if self.config['domain_substrings']:
            parts = href.split('/')
            if len(parts) < 3:
                return False
            domain = parts[2].lower()
            for substring in self.config['domain_substrings']:
                if substring in domain:
                    return True            

    def href_anchors(self):
        '''
        simple, regex-based extractor of anchor tags, so we can
        compute byte offsets for anchor texts and associate them with
        their href.
        
        Generates tuple(href_string, first_byte, byte_length)
        '''
        idx = 0
        new_clean_html = ''
        for m in anchors_re.finditer(self.clean_html):
            before = m.group('before')
            href = m.group('href')
            ahref = m.group('ahref')
            posthref = m.group('posthref')
            preequals = m.group('preequals')
            postequals = m.group('postequals')

            ## construct a text containing bytes up to the anchor text
            ## PLUS ONE NEWLINE
            pre_anchor_increment = before + ahref + preequals + postequals + posthref

            ## increment the index to get line number for the anchor
            idx += len( pre_anchor_increment.splitlines() )
            first = idx

            ## usually this will be one, but it could be more than
            ## that when an anchor text contains newlines
            length = len(m.group('anchor').split('\n'))

            ## construct a replacement clean_html with these newlines
            ## inserted
            new_clean_html += pre_anchor_increment + '\n' + m.group('anchor') + '\n' \
                + m.group('after')

            ## update the index for the next loop
            idx += length - 1 + len( m.group('after').splitlines(True) )

            yield href, first, length, m.group('anchor')

        ## replace clean_html with our new one that has newlines inserted
        self.clean_html = new_clean_html

    def make_label_set(self, clean_html, clean_visible=None):
        '''
        Make a LabelSet for 'author' and the filtered hrefs & anchors
        '''
        annotator = Annotator()
        annotator.annotator_id = 'author'

        labels = []
        ## make clean_html accessible as a class property so we can 
        self.clean_html = clean_html
        for href, first, length, value in self.href_anchors():
            if self.href_filter(href):
                '''
                if clean_visible:
                    _check_html = self.clean_html.splitlines()[first-10:10+first+length]
                    _check_visi =   clean_visible.splitlines()[first:first+length]
                    if not make_clean_visible(_check_html) == _check_visi:
                        print len(self.clean_html.splitlines())
                        print len(clean_visible.splitlines())

                        print href
                        print '\t html: %r' % _check_html
                        print '\t visi: %r' % _check_visi
                '''
                label = Label()
                label.target_id = href
                label.offsets[OffsetType.LINES] = Offset(
                    type=OffsetType.LINES, 
                    first=first, length=length, 
                    value=value,
                    ## the string name of the content field, not the
                    ## content itself :-)
                    content_form='clean_html')
                labels.append(label)

        if labels:
            return LabelSet(annotator=annotator, labels=labels)
        else:
            return None

    def __call__(self, stream_item):
        '''
        Act as an incremental transform in the kba.pipeline
        '''
        if stream_item.body and stream_item.body.clean_html:
            labelset = self.make_label_set(stream_item.body.clean_html,
                                           stream_item.body.clean_visible)
            if labelset:
                ## if we got labels, then we must replace clean_html
                ## with a new one that has newlines inserted
                stream_item.body.clean_html = self.clean_html

                ## add also add the new labelset
                stream_item.body.labelsets.append( labelset )
        return stream_item
